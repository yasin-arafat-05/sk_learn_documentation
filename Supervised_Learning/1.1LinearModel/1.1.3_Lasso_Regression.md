
# Lasso Regression:


### Lasso Regression or Lasso Regularization:

Ridge Regression এর মতোই শুধু penalty হিসাব করার সময়, regression coefficient এর পরির্বতে আমরা মডুলাস value use করবো । Ridge Regression or Ridge Regularization এর সবচেয়ে বড় পাথক্য হলো graph এ দেখবো যে, Lasso Regression এ regression coefficient এর ভ্যালু shrink হয়ে 0 হয়ে যায়  কিন্তু Ridge Regression এ এইটা হয় না । আর যাদের মান 0 হয়ে যাবে সুতরাং y এর ভ্যালু নির্নয় করার জন্য তাদের কোন weight বা importance থাকবে না । এতে feature এর সংখ্যা কমে যাবে এবং Overfitting problem থেকে আমরা মুক্ত হবো । তাই Lasso Regression or Lasso Regularization feature selection এর কাজও করে । 


![Alt text](/Supervised_Learning/1.1LinearModel/images/image2.png)

<br> <br>


1. **Lasso Regression**: The Lasso (Least Absolute Shrinkage and Selection Operator) is a linear model that estimates sparse coefficients. It is particularly useful because it tends to produce solutions with fewer non-zero coefficients, effectively reducing the number of features upon which the solution depends. This property makes it valuable in contexts where feature selection is important, such as in compressed sensing.

2. **Mathematical Formulation**: The objective function of Lasso regression consists of a linear model with an additional regularization term. The regularization term is the \( L_1 \) norm of the coefficient vector multiplied by a constant \( \alpha \). The minimization problem involves minimizing the sum of squared errors (least-squares penalty) along with the added \( L_1 \) penalty.

3. **Implementation**: The scikit-learn implementation of Lasso regression, provided by the `Lasso` class, uses coordinate descent as the algorithm to fit the coefficients. This algorithm efficiently finds the optimal coefficients by iteratively updating each coefficient while holding others fixed.

4. **Usage**: To use Lasso regression in scikit-learn, you create an instance of the `Lasso` class, specifying the value of the regularization parameter \( \alpha \) (also known as the penalty term). Then, you call the `fit()` method with the feature matrix `X` and target vector `y` to train the model. After training, you can use the model to make predictions using the `predict()` method.

5. **Example**: The provided example demonstrates how to use the `Lasso` class in scikit-learn. It creates an instance of `Lasso` with \( \alpha = 0.1 \), fits the model to a dataset containing two data points, and makes a prediction for a new data point.

6. **Additional Functionality**: The `lasso_path` function is mentioned as useful for lower-level tasks. This function computes the coefficients along the full path of possible values, providing insights into how the coefficients change with varying levels of regularization.

