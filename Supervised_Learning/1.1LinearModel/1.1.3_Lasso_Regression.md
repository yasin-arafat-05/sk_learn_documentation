
# Lasso Regression:


### Lasso Regression or Lasso Regularization:

Ridge Regression এর মতোই শুধু penalty হিসাব করার সময়, regression coefficient এর পরির্বতে আমরা মডুলাস value use করবো । Ridge Regression or Ridge Regularization এর সবচেয়ে বড় পাথক্য হলো graph এ দেখবো যে, Lasso Regression এ regression coefficient এর ভ্যালু shrink হয়ে 0 হয়ে যায়  কিন্তু Ridge Regression এ এইটা হয় না । আর যাদের মান 0 হয়ে যাবে সুতরাং y এর ভ্যালু নির্নয় করার জন্য তাদের কোন weight বা importance থাকবে না । এতে feature এর সংখ্যা কমে যাবে এবং Overfitting problem থেকে আমরা মুক্ত হবো । তাই Lasso Regression or Lasso Regularization feature selection এর কাজও করে । 


![Alt text](/Supervised_Learning/1.1LinearModel/images/image2.png)

<br> <br>


1. **Lasso Regression**: The Lasso (Least Absolute Shrinkage and Selection Operator) is a linear model that estimates sparse coefficients **("sparse coefficients" refer to the property where many of the coefficients estimated by the model are set to zero)**. It is particularly useful because it tends to produce solutions with fewer non-zero coefficients, effectively reducing the number of features upon which the solution depends. This property makes it valuable in contexts where feature selection is important, such as in compressed sensing.


2. **Implementation**: The scikit-learn implementation of Lasso regression, provided by the `Lasso` class, uses coordinate descent as the algorithm to fit the coefficients. This algorithm efficiently finds the optimal coefficients by iteratively updating each coefficient while holding others fixed.

3. **Usage**: To use Lasso regression in scikit-learn, you create an instance of the `Lasso` class, specifying the value of the regularization parameter $\( \alpha \)$ (also known as the penalty term). Then, you call the `fit()` method with the feature matrix `X` and target vector `y` to train the model. After training, you can use the model to make predictions using the `predict()` method.

4. **Example**: The provided example demonstrates how to use the `Lasso` class in scikit-learn. It creates an instance of `Lasso` with $\( \alpha = 0.1 \)$, fits the model to a dataset containing two data points, and makes a prediction for a new data point.

```python
from sklearn import linear_model
reg = linear_model.Lasso(alpha=0.1)
reg.fit([[0, 0], [1, 1]], [0, 1])
reg.predict([[1, 1]])
```

5. **Additional Functionality**: The `lasso_path` function is mentioned as useful for lower-level tasks. This function computes the coefficients along the full path of possible values, providing insights into how the coefficients change with varying levels of regularization.

